{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "##################################################################################################\n",
    "\n",
    "\n",
    "### This file and the source code provided can be used only for the projects and assignments  \n",
    "### of this course\n",
    "\n",
    "\n",
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divvy\n",
    "\n",
    "**Divvy** is a bicycle sharing system in the City of Chicago.\n",
    "\n",
    "Click __[here](https://en.wikipedia.org/wiki/Divvy)__ to read more about **Divvy**\n",
    "\n",
    "\n",
    "Click __[here](https://www.divvybikes.com/)__ to visit the official website for **Divvy**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will send a heartbeat every 2 minutes to divvy to collect their stations status in the City of Chicago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get divvy stations status\n",
    "# Status is returned as a json reply\n",
    "\n",
    "response = urllib.request.urlopen('https://feeds.divvybikes.com/stations/stations.json')\n",
    "\n",
    "# Extract the body of the reply\n",
    "response_body = response.read()\n",
    "\n",
    "# Decode the format in json format\n",
    "stations_json = json.loads(response_body.decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(stations_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(stations_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data file into a dataframe\n",
    "df__stations = pd.DataFrame(stations_json['stationBeanList'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data preparation and cleaning**\n",
    "- We need to do some Data preparation and cleaning work\n",
    "- Notice the alltitude is BLANK below\n",
    "- And sometimes we have BLANK zip code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df__stations.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the BLANKs from the data\n",
    "\n",
    "df__stations['altitude'] = df__stations['altitude'].apply(lambda x: 0 if x == '' else x)\n",
    "df__stations['postalCode'] = df__stations['postalCode'].apply(lambda x: 0 if x == '' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "- There is a bug in the divvy data feed ...\n",
    "- Sometimes they add an extra space to the city name\n",
    "- See the following two records from divvy feed; compare the city names\n",
    "\n",
    "\n",
    "['0', '14', '13', **'Chicago'**, '111', 'True', 'K3_FULL', '13052', '2018-12-26 19:20:34', '41.894666', '', '-87.638437', '60654', 'Sedgwick St & Huron St', '', 'Sedgwick St & Huron St', 'IN_SERVICE', '1', 'In Service', 'False', '27']\n",
    "\n",
    "['0', '7', '8', **'Chicago '**, '112', 'True', 'K3_FULL', '13053', '2018-12-26 19:20:49', '41.883668', '', '-87.64867', '60607', 'Green St & Randolph St', '', 'Green St & Randolph St', 'IN_SERVICE', '1', 'In Service', 'False', '15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df__stations.city.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the whitespace from the end of hte city name\n",
    "\n",
    "df__stations['city'] = df__stations['city'].apply(lambda x: 'Chicago' if x == 'Chicago ' else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity Test\n",
    "df__stations.city.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df__stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df__stations.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets store our data subset into a file\n",
    "# This way you have a copy of data stored in a file \n",
    "# that you could use in case you want to debug a problem on the orginal data received\n",
    "\n",
    "df__stations.to_csv('divvy_stations_logs.csv',sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets add the spatial type for the location as Where_IS and store the ST_POINT(latitude,longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is the Heartbeat Loop - Pulls data from divvy every 2 minutes in order to get realtime updates for the different divvy stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_json = df__stations.to_json( orient = 'index' )\n",
    "from elasticsearch import Elasticsearch, helpers \n",
    "for station in df_stations_json:\n",
    "        index_station = {  \n",
    "            \"_index\": \"divvy_stations_logs\",\n",
    "            \"_type\": \"logs\",\n",
    "            \"_id\": station['id'],\n",
    "            \"_source\": station\n",
    "        }\n",
    "        list__station_documents.append(index_station)                      \n",
    "pprint(list__station_documents)\n",
    "\n",
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the bulk document-indexing\n",
    "    \n",
    "helpers.bulk(es, list__business_reviews_documents)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers \n",
    "import time\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Get divvy stations status\n",
    "    # Status is returned as a json reply\n",
    "    response = urllib.request.urlopen('https://feeds.divvybikes.com/stations/stations.json')\n",
    "    \n",
    "    # Extract the body of the reply\n",
    "    response_body = response.read()\n",
    "    \n",
    "    # Decode the format in json format\n",
    "    stations_json = json.loads(response_body.decode(\"utf-8\"))\n",
    "    \n",
    "    # load data file into a dataframe\n",
    "    df__stations = pd.DataFrame(stations_json['stationBeanList'])\n",
    "    \n",
    "    # Clean the BLANKs from the data\n",
    "    df__stations['altitude'] = df__stations['altitude'].apply(lambda x: 0 if x == '' else x)\n",
    "    df__stations['postalCode'] = df__stations['postalCode'].apply(lambda x: 0 if x == '' else x)\n",
    "    \n",
    "    #Remove the whitespace from the end of hte city name\n",
    "    df__stations['city'] = df__stations['city'].apply(lambda x: 'Chicago' if x == 'Chicago ' else x)\n",
    "    \n",
    "    # lets store our data subset into a file\n",
    "    # This way you have a copy of data stored in a file \n",
    "    # that you could use in case you want to debug a problem on the orginal data received\n",
    "    df__stations.to_csv('divvy_stations_logs.csv',sep=',', encoding='utf-8', index=False)\n",
    "    df_stations_json = df__stations.to_json( orient = 'index' )\n",
    "    for station in df_stations_json:\n",
    "        index_station = {\n",
    "            \"_index\": \"divvy_stations_logs\",\n",
    "            \"_type\": \"logs\",\n",
    "            \"_id\": station['id'],\n",
    "            \"_source\": station\n",
    "        }\n",
    "        list__station_documents.append(index_station)                      \n",
    "    pprint(list__station_documents)\n",
    "\n",
    "    es = Elasticsearch()\n",
    "    \n",
    "    # Start the bulk document-indexing\n",
    "    helpers.bulk(es, list__business_reviews_documents) \n",
    "    \n",
    "    # Sleep for 3 minutes; divvy updates its stations status every 2 minutes\n",
    "    print('Sent Heartbeat to Divvy Servers and Going to sleep now ...')\n",
    "    time.sleep(125)    \n",
    "    continue\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
