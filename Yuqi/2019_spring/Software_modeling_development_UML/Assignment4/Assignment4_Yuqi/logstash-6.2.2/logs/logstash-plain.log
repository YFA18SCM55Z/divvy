[2019-04-05T11:05:25,900][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/Users/runze/Desktop/Yuqi/2019_spring/Software_modeling_development_UML/Assignment4/Assignment4_Yuqi/logstash-6.2.2/modules/fb_apache/configuration"}
[2019-04-05T11:05:25,927][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/Users/runze/Desktop/Yuqi/2019_spring/Software_modeling_development_UML/Assignment4/Assignment4_Yuqi/logstash-6.2.2/modules/netflow/configuration"}
[2019-04-05T11:05:26,047][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"/Users/runze/Desktop/Yuqi/2019_spring/Software_modeling_development_UML/Assignment4/Assignment4_Yuqi/logstash-6.2.2/data/queue"}
[2019-04-05T11:05:26,053][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"/Users/runze/Desktop/Yuqi/2019_spring/Software_modeling_development_UML/Assignment4/Assignment4_Yuqi/logstash-6.2.2/data/dead_letter_queue"}
[2019-04-05T11:05:26,224][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-04-05T11:05:26,317][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"f9a22e8e-5470-4234-8420-d47b3c37b3a8", :path=>"/Users/runze/Desktop/Yuqi/2019_spring/Software_modeling_development_UML/Assignment4/Assignment4_Yuqi/logstash-6.2.2/data/uuid"}
[2019-04-05T11:05:27,014][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.2"}
[2019-04-05T11:05:27,488][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-04-05T11:05:31,859][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//localhost:9200], index=>"divvy_stations_logs", document_type=>"logs", id=>"f4872056312d3503a49c5ede91eeed7b4365da5ec34edd8eb61cf66c1ad359ec", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_3900a999-1437-44ce-8b60-742a6846fb42", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-04-05T11:05:33,477][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2019-04-05T11:05:34,055][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2019-04-05T11:05:34,070][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2019-04-05T11:05:34,336][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2019-04-05T11:05:34,431][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>nil}
[2019-04-05T11:05:34,435][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-04-05T11:05:34,456][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2019-04-05T11:05:34,485][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-04-05T11:05:34,546][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2019-04-05T11:05:34,648][INFO ][logstash.inputs.tcp      ] Automatically switching from json to json_lines codec {:plugin=>"tcp"}
[2019-04-05T11:05:34,716][INFO ][logstash.inputs.tcp      ] Starting tcp input listener {:address=>"0.0.0.0:5044", :ssl_enable=>"false"}
[2019-04-05T11:05:34,972][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0xb652a run>"}
[2019-04-05T11:05:35,086][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
[2019-04-05T11:14:21,011][WARN ][logstash.runner          ] SIGINT received. Shutting down.
[2019-04-05T11:14:26,022][WARN ][logstash.runner          ] Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss.
[2019-04-05T11:14:26,296][WARN ][logstash.shutdownwatcher ] {"inflight_count"=>0, "stalling_thread_info"=>{}}
[2019-04-05T11:14:26,321][ERROR][logstash.shutdownwatcher ] The shutdown process appears to be stalled due to busy or blocked plugins. Check the logs for more information.
[2019-04-05T11:14:26,330][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>"main", :thread=>"#<Thread:0xb652a run>"}
[2019-04-05T11:16:15,017][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/Users/runze/Desktop/Yuqi/2019_spring/Software_modeling_development_UML/Assignment4/Assignment4_Yuqi/logstash-6.2.2/modules/fb_apache/configuration"}
[2019-04-05T11:16:15,036][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/Users/runze/Desktop/Yuqi/2019_spring/Software_modeling_development_UML/Assignment4/Assignment4_Yuqi/logstash-6.2.2/modules/netflow/configuration"}
[2019-04-05T11:16:15,313][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2019-04-05T11:16:16,051][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.2.2"}
[2019-04-05T11:16:16,550][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2019-04-05T11:16:19,918][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting "document_type" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>"document_type", :plugin=><LogStash::Outputs::ElasticSearch hosts=>[//localhost:9200], index=>"divvy_stations_logs", document_type=>"logs", id=>"f4872056312d3503a49c5ede91eeed7b4365da5ec34edd8eb61cf66c1ad359ec", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>"plain_2d5cdfdb-bbfc-42bb-b0c3-3eb8525f8b36", enable_metric=>true, charset=>"UTF-8">, workers=>1, manage_template=>true, template_name=>"logstash", template_overwrite=>false, doc_as_upsert=>false, script_type=>"inline", script_lang=>"painless", script_var_name=>"event", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, action=>"index", ssl_certificate_verification=>true, sniffing=>false, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}
[2019-04-05T11:16:21,855][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>50}
[2019-04-05T11:16:22,490][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2019-04-05T11:16:22,509][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2019-04-05T11:16:22,914][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2019-04-05T11:16:23,029][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>nil}
[2019-04-05T11:16:23,033][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}
[2019-04-05T11:16:23,053][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2019-04-05T11:16:23,079][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2019-04-05T11:16:23,160][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2019-04-05T11:16:23,288][INFO ][logstash.inputs.tcp      ] Automatically switching from json to json_lines codec {:plugin=>"tcp"}
[2019-04-05T11:16:23,356][INFO ][logstash.inputs.tcp      ] Starting tcp input listener {:address=>"0.0.0.0:5044", :ssl_enable=>"false"}
[2019-04-05T11:16:23,718][INFO ][logstash.pipeline        ] Pipeline started succesfully {:pipeline_id=>"main", :thread=>"#<Thread:0x762e7b4e run>"}
[2019-04-05T11:16:23,814][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
